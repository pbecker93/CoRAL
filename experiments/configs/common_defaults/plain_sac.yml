---
name: "DEFAULT"
repetitions: 1
iterations: 1
params:
  experiment:
    world_model: "none"
    model_objective: "none"
    agent: "sac"
    seed: 0
    fully_deterministic: False
    save_interval: -1 # -1 means never
  policy:
    project_for_bypass: False
    actor:
      num_layers: 3
      layer_size: 1024
      activation: ELU
      min_std: 0.005
      init_std: 1.0
      apply_mean_scale: False
    critic:
      num_layers: 3
      layer_size: 1024
      activation: ELU
  trainer:
    discount: 0.99
    target_critic_decay: 0.995
    target_critic_interval: 1
    actor_learning_rate: 0.0003
    actor_clip_norm: 1000.0
    actor_weight_decay: 0.0
    critic_learning_rate: 0.0003
    critic_clip_norm: 100.0
    #eval_interval: -1.0
    entropy:
      learning_rate: 0.001
      clip_norm: 1.0
      learn_bonus: True
      bonus: 0.1
  rl:
    rl_exp:
      normalize_obs: False
      bypass_mask: [True]
      model_updt_seq_length: 2
      model_updt_batch_size: 256
      model_updt_steps: 100
      replay_buffer_size: -1
    initial_data_collection:
      num_sequences: 10
      seq_length: -1
    data_collection:
      seq_length: -1
      num_sequences: 1
    img_preprocessing:
      type: "none"
      add_cb_noise: False
      color_depth_bits: 8
  policy_eval:
    reward_eval:
      eval_interval: 20
      num_sequences: 20
      use_mean: True
      record_vid: False
      max_sequence_length: -1
